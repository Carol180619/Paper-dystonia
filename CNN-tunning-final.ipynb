{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976a6ff3",
   "metadata": {},
   "source": [
    "# IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from igraph import plot\n",
    "from igraph import drawing\n",
    "#import cairo\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from igraph import Graph\n",
    "from numpy import matrix\n",
    "import pandas as pd\n",
    "from kerastuner import HyperModel\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from keras.utils import np_utils\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from pandas import DataFrame\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kerastuner as kt\n",
    "from pandas import DataFrame\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling2D\n",
    ")\n",
    "from kerastuner.tuners import Hyperband\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import kerastuner as kt\n",
    "from sklearn import covariance, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7698db8c",
   "metadata": {},
   "source": [
    "# READ FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pixels_from_path(file_path):\n",
    "    im = open(file_path)\n",
    "    test = pd.read_csv(im,sep=\",\", index_col=False,header=None)\n",
    "    #im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(test)\n",
    "    #matrix of pixel RGB values\n",
    "    return np_im\n",
    "\n",
    "print(\"Dystonia\")\n",
    "dystonia = np.asarray([pixels_from_path(n) for n in glob.glob(r'INSERT MATRICES DYSTONIA FOLDER PATH')])\n",
    "print(dystonia)\n",
    "print(np.shape(dystonia))\n",
    "print(\"Normal\")\n",
    "normal = np.asarray([pixels_from_path(n) for n in glob.glob(r'INSERT MATRICES NORMAL FOLDER PATH')])\n",
    "print(normal)\n",
    "print(np.shape(normal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bb769",
   "metadata": {},
   "source": [
    "# PREPARING TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438152b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([normal ,dystonia])\n",
    "print(np.shape(x_train))\n",
    "myScaler = preprocessing.StandardScaler()\n",
    "x_train=myScaler.fit_transform(i)\n",
    "x=np.nan_to_num(x_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d05115",
   "metadata": {},
   "source": [
    "# PREPARING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = [1]*len(dystonia)\n",
    "no_disease = [0]*len(normal)\n",
    "labels = disease + no_disease \n",
    "print(len(labels))## the labels of the graphs\n",
    "y=np.nan_to_num(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24557e06",
   "metadata": {},
   "source": [
    "# SPLIT TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c68489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed023f2",
   "metadata": {},
   "source": [
    "# DEFINE CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfda194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.01,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=hp.Choice(\n",
    "                    'num_filters',\n",
    "                    values=[32, 64],\n",
    "                    default=64,\n",
    "                ),\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_2',\n",
    "                min_value=0.05,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.001,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=METRICS\n",
    "        )\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec37e4",
   "metadata": {},
   "source": [
    "# CALL THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33483496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 1\n",
    "NUM_CLASSES = 2  #\n",
    "HYPERBAND_MAX_EPOCHS = 100\n",
    "MAX_TRIALS = 100\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "INPUT_SHAPE = (32, 32, 1) \n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(x, y, stratify=y, test_size=0.10)\n",
    "skfold = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skfold.split(X_train,Y_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "    print(np.shape(x_train))\n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "    #count_classes = y_test.shape[1]\n",
    "    x_test = x_test.reshape(-1, 32, 32, 1)\n",
    "    x_train = x_train.reshape(-1, 32, 32, 1)\n",
    "    \n",
    " \n",
    "\n",
    "    hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "    tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    seed=SEED,\n",
    "    max_trials=MAX_TRIALS,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "   \n",
    "     \n",
    "    overwrite = True  \n",
    "\n",
    "    )\n",
    "    tuner.search(x_train, y_train, epochs=100,  validation_data=(x_test,y_test), verbose=0)\n",
    "    best_model_rs = tuner.get_best_models(num_models=1)[0]\n",
    "#tuner.results_summary()\n",
    "# Retrieve the best model.\n",
    "    best_model_rs = tuner.get_best_models(num_models=1)[0]\n",
    "    history_rs=best_model_rs.fit(x_train,y_train, epochs=1000, validation_data=(x_test,y_test))\n",
    "    print(best_model_rs.evaluate(x_train, y_train))\n",
    "    \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab5114",
   "metadata": {},
   "source": [
    "# RESULTS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c385c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rs.evaluate(x_train, y_train)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "Y_test = to_categorical(Y_test)\n",
    "best_model_rs.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae3244",
   "metadata": {},
   "source": [
    "# ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80747b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style('whitegrid')\n",
    "y_score= best_model_rs.predict(X_test)\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "n_classes=2\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.figure(1)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='slategray', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['purple', 'lightseagreen'])\n",
    "list_names=['HC','ULD']\n",
    "for i, color, name in zip(range(n_classes), colors,list_names):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "        label=\"ROC curve of class \"+ name + \" (area = {1:0.2f})\".format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',color='#cb416b', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.annotate(' Random Guess',(.5,.48),color='#cb416b')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver Operating Characteristic for Suport Vector Machine')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"dystonia-cnn-tunned-roc.pdf\",dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b46541",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score=np.argmax(y_score, axis=1)\n",
    "Y_test=np.argmax(Y_test, axis=1)\n",
    "cm = metrics.confusion_matrix(y_score, Y_test)\n",
    "\n",
    "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "cm_perc = cm / cm_sum.astype(float) * 100\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "nrows, ncols = cm.shape\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        c = cm[i, j]\n",
    "        p = cm_perc[i, j]\n",
    "        if i == j:\n",
    "            s = cm_sum[i]\n",
    "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "        elif c == 0:\n",
    "            annot[i, j] = ''\n",
    "        else:\n",
    "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "cm = pd.DataFrame(cm)\n",
    "print(cm)\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "#fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.heatmap(cm, annot=annot, fmt='',cmap='rocket_r')\n",
    "plt.savefig(\"dystonia-cnn-tunned-confusion-matrix.pdf\",dpi=300, bbox_inches = \"tight\",xticklabels=list_names, yticklabels=list_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c58857",
   "metadata": {},
   "source": [
    "# LEARNING CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c172bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "acc = history_rs.history['accuracy']\n",
    "val_acc =history_rs.history['val_accuracy']\n",
    "loss = history_rs.history['loss']\n",
    "val_loss = history_rs.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"dystonia-cnn-tunned-leaning-curve.pdf\",dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80080e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
